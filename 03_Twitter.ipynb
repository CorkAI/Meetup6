{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter\n",
    "\n",
    "Twitter API allows to fetch live tweets by keyword, or to fetch a 1/6th sample of all twitter traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "CONSUMER_KEY = os.environ['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = os.environ['CONSUMER_SECRET']\n",
    "TWITTER_TOKEN = os.environ['TWITTER_TOKEN']\n",
    "TWITTER_SECRET = os.environ['TWITTER_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import twitter\n",
    "\n",
    "# create new twitter stream\n",
    "stream = twitter.TwitterStream(\n",
    "    timeout=3600,\n",
    "    heartbeat_timeout=3600,\n",
    "    auth=twitter.OAuth(TWITTER_TOKEN,\n",
    "                       TWITTER_SECRET,\n",
    "                       CONSUMER_KEY,\n",
    "                       CONSUMER_SECRET))\n",
    "\n",
    "def get_tweets(terms):\n",
    "    \"\"\"\n",
    "    stream all tweets (within 1/6th quota) indefinitely that contain any of the `terms`.\n",
    "    \n",
    "    `statuses.filter` doesn't always return correct matches, so we have to double-check ;)\n",
    "    \"\"\"\n",
    "    # NOTE: using weird syntax instead of '\\b' for non-word-boundaries (i.e. starting with '#')\n",
    "    rex = re.compile(\n",
    "        r'(?:^|[\\W\\D]|$)(?:%s)(?:^|[\\W\\D]|$)' % ('|'.join(re.escape(k) for k in terms),),\n",
    "        flags=re.I)\n",
    "    track = ','.join(terms)\n",
    "    \n",
    "    for tweet in stream.statuses.filter(track=track):\n",
    "        text = tweet.get('extended_tweet', {}).get('full_text') or tweet.get('text')\n",
    "        if tweet.get('lang') == 'en' and rex.search(text):\n",
    "            yield tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Filtering\n",
    "\n",
    "We are looking for all current live tweets that contain the following keywords.\n",
    "Let's see how long it will take to fetch 10 live tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5865d9366e1748e7a91a5e7cdb982e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "terms = [\n",
    "    '#BigData',\n",
    "    '#MachineLearning',\n",
    "    'machine learning',\n",
    "    'deep learning',\n",
    "    'artificial intelligence',\n",
    "    'data science',\n",
    "    '#ml',\n",
    "    '#deeplearning',\n",
    "    '#datascience',\n",
    "    '#machinelearning',\n",
    "    'natural language processing'\n",
    "]\n",
    "\n",
    "    \n",
    "res = tqdm_notebook(get_tweets(terms))\n",
    "res = list(islice(res, 10))\n",
    "\n",
    "del stream  # stream.stop()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Structure\n",
    "\n",
    "A tweet contains a lot of data and metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"created_at\": \"Tue Sep 25 23:12:41 +0000 2018\",\n",
      "    \"id\": 1044726414572965888,\n",
      "    \"id_str\": \"1044726414572965888\",\n",
      "    \"text\": \"Transforming Businesses with Artificial Intelligence https://t.co/r5e5mVIu0m\",\n",
      "    \"source\": \"<a href=\\\"https://www.zift123.com\\\" rel=\\\"nofollow\\\">Zift123 Platform</a>\",\n",
      "    \"truncated\": false,\n",
      "    \"in_reply_to_status_id\": null,\n",
      "    \"in_reply_to_status_id_str\": null,\n",
      "    \"in_reply_to_user_id\": null,\n",
      "    \"in_reply_to_user_id_str\": null,\n",
      "    \"in_reply_to_screen_name\": null,\n",
      "    \"user\": {\n",
      "        \"id\": 11975452,\n",
      "        \"id_str\": \"11975452\",\n",
      "        \"name\": \"Jeremy Murtishaw\",\n",
      "        \"screen_name\": \"murtishaw\",\n",
      "        \"location\": \"\\u00dcT: 33.790969,-84.391181\",\n",
      "        \"url\": \"http://about.me/murtishaw\",\n",
      "        \"description\": \"Technologist specializing in Healthcare IT, Network Design and Security, Cloud Computing, Hosting.  2020 Presidential Candidate.\",\n",
      "        \"translator_type\": \"none\",\n",
      "        \"protected\": false,\n",
      "        \"verified\": false,\n",
      "        \"followers_count\": 4664,\n",
      "        \"friends_count\": 1829,\n",
      "        \"listed_count\": 201,\n",
      "        \"favourites_count\": 39,\n",
      "        \"statuses_count\": 20013,\n",
      "        \"created_at\": \"Tue Jan 08 06:20:32 +0000 2008\",\n",
      "        \"utc_offset\": null,\n",
      "        \"time_zone\": null,\n",
      "        \"geo_enabled\": false,\n",
      "        \"lang\": \"en\",\n",
      "        \"contributors_enabled\": false,\n",
      "        \"is_translator\": false,\n",
      "        \"profile_background_color\": \"C0DEED\",\n",
      "        \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "        \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "        \"profile_background_tile\": true,\n",
      "        \"profile_link_color\": \"0084B4\",\n",
      "        \"profile_sidebar_border_color\": \"C0DEED\",\n",
      "        \"profile_sidebar_fill_color\": \"DDEEF6\",\n",
      "        \"profile_text_color\": \"333333\",\n",
      "        \"profile_use_background_image\": true,\n",
      "        \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1160089290/MyPicture_normal.jpg\",\n",
      "        \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1160089290/MyPicture_normal.jpg\",\n",
      "        \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/11975452/1396221833\",\n",
      "        \"default_profile\": false,\n",
      "        \"default_profile_image\": false,\n",
      "        \"following\": null,\n",
      "        \"follow_request_sent\": null,\n",
      "        \"notifications\": null\n",
      "    },\n",
      "    \"geo\": null,\n",
      "    \"coordinates\": null,\n",
      "    \"place\": null,\n",
      "    \"contributors\": null,\n",
      "    \"is_quote_status\": false,\n",
      "    \"quote_count\": 0,\n",
      "    \"reply_count\": 0,\n",
      "    \"retweet_count\": 0,\n",
      "    \"favorite_count\": 0,\n",
      "    \"entities\": {\n",
      "        \"hashtags\": [],\n",
      "        \"urls\": [\n",
      "            {\n",
      "                \"url\": \"https://t.co/r5e5mVIu0m\",\n",
      "                \"expanded_url\": \"https://oal.lu/GcRln\",\n",
      "                \"display_url\": \"oal.lu/GcRln\",\n",
      "                \"indices\": [\n",
      "                    53,\n",
      "                    76\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"user_mentions\": [],\n",
      "        \"symbols\": []\n",
      "    },\n",
      "    \"favorited\": false,\n",
      "    \"retweeted\": false,\n",
      "    \"possibly_sensitive\": false,\n",
      "    \"filter_level\": \"low\",\n",
      "    \"lang\": \"en\",\n",
      "    \"timestamp_ms\": \"1537917161969\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(res[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matched Tweets\n",
    "\n",
    "Let's look at some of the tweet texts we have captured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>murtishaw</td>\n",
       "      <td>Transforming Businesses with Artificial Intelligence https://t.co/r5e5mVIu0m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CyberSecManaged</td>\n",
       "      <td>Transforming Businesses with Artificial Intelligence https://t.co/8AmvarmQzL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fortify_24x7</td>\n",
       "      <td>Transforming Businesses with Artificial Intelligence https://t.co/I9MmHk4Z4x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rstatstweet</td>\n",
       "      <td>RT @Rbloggers: R developer’s guide to Azure https://t.co/w5xEi85UAb #rstats #DataScience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everwood_lynn</td>\n",
       "      <td>RT @intel: Preserving the Great Wall is an almost impossible task, one that our team is attempting to solve using artificial intelligence a…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TechnoJeder</td>\n",
       "      <td>RT @SacTechEvents: Who's going to the Sacramento Artificial Intelligence meetup on Sunday? Join us: https://t.co/MWDeTLczDh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TechnoJeder</td>\n",
       "      <td>RT @AccendNetworks: Transforming Businesses with Artificial Intelligence https://t.co/TFk3Sz7nLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datatalentrec</td>\n",
       "      <td>Should We Be Afraid Of Artificial Intelligence?\\n#MachineLearning #ArtificialInteligence #Robots #machineintelligence \\nhttps://t.co/QgqW2itVXS https://t.co/ZbqDYqlzA3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TechnoJeder</td>\n",
       "      <td>RT @neocompsystems: Transforming Businesses with Artificial Intelligence https://t.co/dbY1zUU3gn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>clive140</td>\n",
       "      <td>RT @MikeQuindazzi: Next-gen #SelfDrivingCars see trouble around the corner, literally! &amp;gt;&amp;gt; @MikeQuindazzi &amp;gt;&amp;gt; #AI #MachineLearning #DeepLearn…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  \\\n",
       "0        murtishaw   \n",
       "1  CyberSecManaged   \n",
       "2     fortify_24x7   \n",
       "3      rstatstweet   \n",
       "4    everwood_lynn   \n",
       "5      TechnoJeder   \n",
       "6      TechnoJeder   \n",
       "7    datatalentrec   \n",
       "8      TechnoJeder   \n",
       "9         clive140   \n",
       "\n",
       "                                                                                                                                                                      text  \n",
       "0                                                                                             Transforming Businesses with Artificial Intelligence https://t.co/r5e5mVIu0m  \n",
       "1                                                                                             Transforming Businesses with Artificial Intelligence https://t.co/8AmvarmQzL  \n",
       "2                                                                                             Transforming Businesses with Artificial Intelligence https://t.co/I9MmHk4Z4x  \n",
       "3                                                                                 RT @Rbloggers: R developer’s guide to Azure https://t.co/w5xEi85UAb #rstats #DataScience  \n",
       "4                             RT @intel: Preserving the Great Wall is an almost impossible task, one that our team is attempting to solve using artificial intelligence a…  \n",
       "5                                              RT @SacTechEvents: Who's going to the Sacramento Artificial Intelligence meetup on Sunday? Join us: https://t.co/MWDeTLczDh  \n",
       "6                                                                         RT @AccendNetworks: Transforming Businesses with Artificial Intelligence https://t.co/TFk3Sz7nLY  \n",
       "7  Should We Be Afraid Of Artificial Intelligence?\\n#MachineLearning #ArtificialInteligence #Robots #machineintelligence \\nhttps://t.co/QgqW2itVXS https://t.co/ZbqDYqlzA3  \n",
       "8                                                                         RT @neocompsystems: Transforming Businesses with Artificial Intelligence https://t.co/dbY1zUU3gn  \n",
       "9                 RT @MikeQuindazzi: Next-gen #SelfDrivingCars see trouble around the corner, literally! &gt;&gt; @MikeQuindazzi &gt;&gt; #AI #MachineLearning #DeepLearn…  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 280\n",
    "\n",
    "\n",
    "def prep_tweets(tweets):\n",
    "    \"\"\"\n",
    "    extract fields of interests from tweets\n",
    "    \"\"\"\n",
    "    for tweet in tweets:\n",
    "        yield {\n",
    "            'text': tweet.get('extended_tweet', {}).get('full_text') or tweet.get('text'),\n",
    "            'author': tweet.get('user', {}).get('screen_name'),\n",
    "            #'lang': tweet.get('lang'),\n",
    "            # 'urls': [x.get('expanded_url') or x.get('url') for x in tweet.get('entities', {}).get('urls')]\n",
    "        }\n",
    "\n",
    "        \n",
    "prepped = list(prep_tweets(res))\n",
    "pd.DataFrame(prepped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "Find which hashtags occur most frequently in our matched tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bigdata</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machinelearning</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iot</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datascience</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deeplearning</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ml</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>artificialintelligence</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fintech</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blockchain</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tech</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>robotics</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iiot</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>robots</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>analytics</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nlp</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>insurtech</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dl</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>digitaltransformation</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jobs</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>innovation</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hiring</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cryptocurrency</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>careers</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>technology</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>infographic</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cybersecurity</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>infographics</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0    1\n",
       "0                       ai  771\n",
       "1                  bigdata  555\n",
       "2          machinelearning  532\n",
       "3                      iot  344\n",
       "4              datascience  339\n",
       "5             deeplearning  294\n",
       "6                       ml  198\n",
       "7   artificialintelligence  169\n",
       "8                  fintech  165\n",
       "9               blockchain  138\n",
       "10                    tech  119\n",
       "11                robotics   86\n",
       "12                    iiot   84\n",
       "13                  robots   82\n",
       "14               analytics   65\n",
       "15                     nlp   63\n",
       "16               insurtech   58\n",
       "17                      dl   53\n",
       "18   digitaltransformation   52\n",
       "19                    data   52\n",
       "20                    jobs   52\n",
       "21              innovation   51\n",
       "22                  hiring   49\n",
       "23                 bitcoin   47\n",
       "24          cryptocurrency   47\n",
       "25                 careers   46\n",
       "26              technology   45\n",
       "27             infographic   43\n",
       "28           cybersecurity   41\n",
       "29            infographics   40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_tweets():\n",
    "    \"\"\"\n",
    "    load matched tweets from file\n",
    "    \"\"\"\n",
    "    with gzip.open('data/machine_learning-2018-09-26.jl.gz', 'rt') as fhandle:\n",
    "        for line in fhandle:\n",
    "            yield json.loads(line)\n",
    "\n",
    "            \n",
    "def hashtags(elt):\n",
    "    \"\"\"\n",
    "    get all hashtags from deep within tweet (extended_tweet, retweets, etc.)\n",
    "    \"\"\"\n",
    "    if isinstance(elt, list):\n",
    "        for x in elt:\n",
    "            yield from hashtags(x)\n",
    "    elif isinstance(elt, dict):\n",
    "        if 'hashtags' in elt:\n",
    "            yield [x.get('text').lower() for x in elt['hashtags']]\n",
    "        for v in elt.values():\n",
    "            yield from hashtags(v)\n",
    "            \n",
    "            \n",
    "tweets = list(islice(get_tweets(), 1000))\n",
    "hashtags_per_tweet = [sum(hashtags(tweet), []) for tweet in tweets]\n",
    "all_hashtags = sum(hashtags_per_tweet, []) \n",
    "ctr = Counter(all_hashtags)\n",
    "pd.DataFrame(ctr.most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging Twitter Data\n",
    "\n",
    "Based on the Twitter data we can generate many potential use cases:\n",
    "\n",
    "* [Matched Tweets per Day](https://fluquid.com:5000/twitter)\n",
    "* [DeepMoji](https://github.com/bfelbo/DeepMoji)\n",
    "* Find job offerings\n",
    "* Build a social graph of tweeters\n",
    "* Engage with trending tweets, conversations in your niche\n",
    "* Build live language models, sentiment analysis i.e. for elections\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
